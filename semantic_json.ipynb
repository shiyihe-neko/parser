{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "from typing import Any, Dict, List, Union, Optional\n",
    "import demjson3\n",
    "import json5\n",
    "import hjson\n",
    "import os \n",
    "\n",
    "\n",
    "\n",
    "writing_config=pd.read_csv('/Users/shiyi.he/Desktop/PARSER/writing_norm_config.csv')\n",
    "writing_tabular=pd.read_csv('/Users/shiyi.he/Desktop/PARSER/writing_norm_tabular.csv')\n",
    "\n",
    "writing_config_json=writing_config[['participantId','format','code']][writing_config['format']=='json']\n",
    "writing_tabular_json=writing_tabular[['participantId','format','code']][writing_tabular['format']=='json']\n",
    "writing_config_jsonc=writing_config[['participantId','format','code']][writing_config['format']=='jsonc']\n",
    "writing_tabular_jsonc=writing_tabular[['participantId','format','code']][writing_tabular['format']=='jsonc']\n",
    "writing_config_json5=writing_config[['participantId','format','code']][writing_config['format']=='json5']\n",
    "writing_tabular_json5=writing_tabular[['participantId','format','code']][writing_tabular['format']=='json5']\n",
    "writing_config_hjson=writing_config[['participantId','format','code']][writing_config['format']=='hjson']\n",
    "writing_tabular_hjson=writing_tabular[['participantId','format','code']][writing_tabular['format']=='hjson']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "from typing import Any, Dict, List, Union, Optional\n",
    "import demjson3\n",
    "import json5\n",
    "import hjson\n",
    "\n",
    "\n",
    "\n",
    "# with open(\"test_cases_jsonc.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "#     df_test_cases_jsonc_load = json.load(f)\n",
    "# # Create DataFrame\n",
    "# df_test_cases_jsonc = pd.DataFrame(df_test_cases_jsonc_load)\n",
    "\n",
    "# modifying_config=pd.read_csv('/Users/shiyi.he/Desktop/PARSER/modifying_config.csv')\n",
    "# modifying_tabular=pd.read_csv('/Users/shiyi.he/Desktop/PARSER/modifying_tabular.csv')\n",
    "\n",
    "\n",
    "modifying_config=pd.read_csv('/Users/shiyi.he/Desktop/PARSER/modifying_config_nonempty.csv')\n",
    "modifying_tabular=pd.read_csv('/Users/shiyi.he/Desktop/PARSER/modifying_tabular_nonempty.csv')\n",
    "\n",
    "modifying_tabular_json5_1=modifying_tabular[['participantId','format','code','task']][(modifying_tabular['format']=='json5')& (modifying_tabular['task']=='modifying-task-tabular-1')]\n",
    "modifying_config_json5_1=modifying_config[['participantId','format','code','task']][(modifying_config['format']=='json5')& (modifying_config['task']=='modifying-task-config-1')]\n",
    "modifying_tabular_json5_2=modifying_tabular[['participantId','format','code','task']][(modifying_tabular['format']=='json5')& (modifying_tabular['task']=='modifying-task-tabular-2')]\n",
    "modifying_config_json5_2=modifying_config[['participantId','format','code','task']][(modifying_config['format']=='json5')& (modifying_config['task']=='modifying-task-config-2')]\n",
    "modifying_tabular_json5_3=modifying_tabular[['participantId','format','code','task']][(modifying_tabular['format']=='json5')& (modifying_tabular['task']=='modifying-task-tabular-3')]\n",
    "modifying_config_json5_3=modifying_config[['participantId','format','code','task']][(modifying_config['format']=='json5')& (modifying_config['task']=='modifying-task-config-3')]\n",
    "modifying_tabular_json5_4=modifying_tabular[['participantId','format','code','task']][(modifying_tabular['format']=='json5')& (modifying_tabular['task']=='modifying-task-tabular-4')]\n",
    "modifying_config_json5_4=modifying_config[['participantId','format','code','task']][(modifying_config['format']=='json5')& (modifying_config['task']=='modifying-task-config-4')]\n",
    "modifying_config_json_1=modifying_config[['participantId','format','code','task']][(modifying_config['format']=='json')& (modifying_config['task']=='modifying-task-config-1')]\n",
    "modifying_tabular_json_1=modifying_tabular[['participantId','format','code','task']][(modifying_tabular['format']=='json')& (modifying_tabular['task']=='modifying-task-tabular-1')]\n",
    "modifying_config_json_2=modifying_config[['participantId','format','code','task']][(modifying_config['format']=='json')& (modifying_config['task']=='modifying-task-config-2')]\n",
    "modifying_tabular_json_2=modifying_tabular[['participantId','format','code','task']][(modifying_tabular['format']=='json')& (modifying_tabular['task']=='modifying-task-tabular-2')]\n",
    "modifying_config_json_3=modifying_config[['participantId','format','code','task']][(modifying_config['format']=='json')& (modifying_config['task']=='modifying-task-config-3')]\n",
    "modifying_tabular_json_3=modifying_tabular[['participantId','format','code','task']][(modifying_tabular['format']=='json')& (modifying_tabular['task']=='modifying-task-tabular-3')]\n",
    "modifying_config_json_4=modifying_config[['participantId','format','code','task']][(modifying_config['format']=='json')& (modifying_config['task']=='modifying-task-config-4')]\n",
    "modifying_tabular_json_4=modifying_tabular[['participantId','format','code','task']][(modifying_tabular['format']=='json')& (modifying_tabular['task']=='modifying-task-tabular-4')]\n",
    "modifying_config_jsonc_1=modifying_config[['participantId','format','code','task']][(modifying_config['format']=='jsonc')& (modifying_config['task']=='modifying-task-config-1')]\n",
    "modifying_tabular_jsonc_1=modifying_tabular[['participantId','format','code','task']][(modifying_tabular['format']=='jsonc')& (modifying_tabular['task']=='modifying-task-tabular-1')]\n",
    "modifying_config_jsonc_2=modifying_config[['participantId','format','code','task']][(modifying_config['format']=='jsonc')& (modifying_config['task']=='modifying-task-config-2')]\n",
    "modifying_tabular_jsonc_2=modifying_tabular[['participantId','format','code','task']][(modifying_tabular['format']=='jsonc')& (modifying_tabular['task']=='modifying-task-tabular-2')]\n",
    "modifying_config_jsonc_3=modifying_config[['participantId','format','code','task']][(modifying_config['format']=='jsonc')& (modifying_config['task']=='modifying-task-config-3')]\n",
    "modifying_tabular_jsonc_3=modifying_tabular[['participantId','format','code','task']][(modifying_tabular['format']=='jsonc')& (modifying_tabular['task']=='modifying-task-tabular-3')]\n",
    "modifying_config_jsonc_4=modifying_config[['participantId','format','code','task']][(modifying_config['format']=='jsonc')& (modifying_config['task']=='modifying-task-config-4')]\n",
    "modifying_tabular_jsonc_4=modifying_tabular[['participantId','format','code','task']][(modifying_tabular['format']=='jsonc')& (modifying_tabular['task']=='modifying-task-tabular-4')]\n",
    "modifying_config_hjson_1=modifying_config[['participantId','format','code','task']][(modifying_config['format']=='hjson')& (modifying_config['task']=='modifying-task-config-1')]\n",
    "modifying_tabular_hjson_1=modifying_tabular[['participantId','format','code','task']][(modifying_tabular['format']=='hjson')& (modifying_tabular['task']=='modifying-task-tabular-1')]\n",
    "modifying_config_hjson_2=modifying_config[['participantId','format','code','task']][(modifying_config['format']=='hjson')& (modifying_config['task']=='modifying-task-config-2')]\n",
    "modifying_tabular_hjson_2=modifying_tabular[['participantId','format','code','task']][(modifying_tabular['format']=='hjson')& (modifying_tabular['task']=='modifying-task-tabular-2')]\n",
    "modifying_config_hjson_3=modifying_config[['participantId','format','code','task']][(modifying_config['format']=='hjson')& (modifying_config['task']=='modifying-task-config-3')]\n",
    "modifying_tabular_hjson_3=modifying_tabular[['participantId','format','code','task']][(modifying_tabular['format']=='hjson')& (modifying_tabular['task']=='modifying-task-tabular-3')]\n",
    "modifying_config_hjson_4=modifying_config[['participantId','format','code','task']][(modifying_config['format']=='hjson')& (modifying_config['task']=='modifying-task-config-4')]\n",
    "modifying_tabular_hjson_4=modifying_tabular[['participantId','format','code','task']][(modifying_tabular['format']=='hjson')& (modifying_tabular['task']=='modifying-task-tabular-4')]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## no tree-sitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CleanJSONParser:\n",
    "    \"\"\"纯净的JSON解析器，始终返回可比较的JSON格式\"\"\"\n",
    "    \n",
    "    def parse(self, text: str) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        解析文本为JSON格式\n",
    "        返回：纯净的dict，不包含任何解析状态标记\n",
    "        \"\"\"\n",
    "        if not text or not isinstance(text, str):\n",
    "            return {}\n",
    "        \n",
    "        text = text.strip()\n",
    "        if not text:\n",
    "            return {}\n",
    "        \n",
    "        # 步骤1：尝试最宽松的解析器\n",
    "        result = self._try_lenient_parsers(text)\n",
    "        if result is not None:\n",
    "            return result\n",
    "        \n",
    "        # 步骤2：清理文本后再次尝试\n",
    "        cleaned_text = self._clean_text(text)\n",
    "        result = self._try_lenient_parsers(cleaned_text)\n",
    "        if result is not None:\n",
    "            return result\n",
    "        \n",
    "        # 步骤3：使用正则表达式提取结构\n",
    "        result = self._extract_structure(text)\n",
    "        return result\n",
    "    \n",
    "    def _try_lenient_parsers(self, text: str) -> Union[Dict, None]:\n",
    "        \"\"\"按照从最宽松到最严格的顺序尝试解析器\"\"\"\n",
    "        # 1. 尝试demjson3（最宽松）\n",
    "        try:\n",
    "            result = demjson3.decode(text)\n",
    "            # 确保返回的是dict\n",
    "            if isinstance(result, dict):\n",
    "                return result\n",
    "            elif isinstance(result, list):\n",
    "                return {\"items\": result}\n",
    "            else:\n",
    "                return {\"value\": result}\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # 2. 尝试HJSON（人类友好的JSON）\n",
    "        try:\n",
    "            result = hjson.loads(text)\n",
    "            if isinstance(result, dict):\n",
    "                return result\n",
    "            elif isinstance(result, list):\n",
    "                return {\"items\": result}\n",
    "            else:\n",
    "                return {\"value\": result}\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # 3. 尝试JSON5（支持更宽松的语法）\n",
    "        try:\n",
    "            result = json5.loads(text)\n",
    "            if isinstance(result, dict):\n",
    "                return result\n",
    "            elif isinstance(result, list):\n",
    "                return {\"items\": result}\n",
    "            else:\n",
    "                return {\"value\": result}\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def _clean_text(self, text: str) -> str:\n",
    "        \"\"\"清理文本，修复常见的语法错误\"\"\"\n",
    "        # 移除注释\n",
    "        text = re.sub(r'//.*?$', '', text, flags=re.MULTILINE)\n",
    "        text = re.sub(r'/\\*.*?\\*/', '', text, flags=re.DOTALL)\n",
    "        \n",
    "        # 修复引号问题\n",
    "        # 将开头的双单引号改为双引号\n",
    "        text = re.sub(r\"^''\", '\"', text)\n",
    "        \n",
    "        # 修复尾随逗号\n",
    "        text = re.sub(r',(\\s*[}\\]])', r'\\1', text)\n",
    "        \n",
    "        # 修复缺失的逗号\n",
    "        # \"key1\": \"value1\" \"key2\": \"value2\" -> \"key1\": \"value1\", \"key2\": \"value2\"\n",
    "        text = re.sub(r'([\"\\d\\]\\}])\\s*\\n?\\s*(\")', r'\\1,\\2', text)\n",
    "        text = re.sub(r'([\"\\d\\]\\}])\\s+([\"\\w])', r'\\1, \\2', text)\n",
    "        \n",
    "        # 修复缺失的冒号\n",
    "        # \"key\" \"value\" -> \"key\": \"value\"\n",
    "        text = re.sub(r'\"([^\"]+)\"\\s+\"', r'\"\\1\": \"', text)\n",
    "        \n",
    "        # 确保文本有外层括号\n",
    "        text = text.strip()\n",
    "        if text and not text.startswith('{') and not text.startswith('['):\n",
    "            # 检查是否看起来像对象\n",
    "            if ':' in text:\n",
    "                text = '{' + text + '}'\n",
    "        \n",
    "        # 平衡括号\n",
    "        return self._balance_brackets(text)\n",
    "    \n",
    "    def _balance_brackets(self, text: str) -> str:\n",
    "        \"\"\"平衡括号和引号\"\"\"\n",
    "        # 统计括号\n",
    "        brace_count = 0\n",
    "        bracket_count = 0\n",
    "        quote_count = 0\n",
    "        in_string = False\n",
    "        escape = False\n",
    "        \n",
    "        for char in text:\n",
    "            if escape:\n",
    "                escape = False\n",
    "                continue\n",
    "            \n",
    "            if char == '\\\\':\n",
    "                escape = True\n",
    "                continue\n",
    "            \n",
    "            if char == '\"' and not in_string:\n",
    "                in_string = True\n",
    "                quote_count += 1\n",
    "            elif char == '\"' and in_string:\n",
    "                in_string = False\n",
    "                quote_count += 1\n",
    "            elif not in_string:\n",
    "                if char == '{':\n",
    "                    brace_count += 1\n",
    "                elif char == '}':\n",
    "                    brace_count -= 1\n",
    "                elif char == '[':\n",
    "                    bracket_count += 1\n",
    "                elif char == ']':\n",
    "                    bracket_count -= 1\n",
    "        \n",
    "        # 添加缺失的闭合符号\n",
    "        if brace_count > 0:\n",
    "            text += '}' * brace_count\n",
    "        if bracket_count > 0:\n",
    "            text += ']' * bracket_count\n",
    "        if quote_count % 2 != 0:\n",
    "            text += '\"'\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    def _extract_structure(self, text: str) -> Dict[str, Any]:\n",
    "        \"\"\"使用正则表达式提取JSON结构\"\"\"\n",
    "        result = {}\n",
    "        \n",
    "        # 策略1：提取标准的键值对\n",
    "        self._extract_key_value_pairs(text, result)\n",
    "        \n",
    "        # 策略2：提取数组\n",
    "        self._extract_arrays(text, result)\n",
    "        \n",
    "        # 策略3：提取嵌套对象\n",
    "        self._extract_nested_objects(text, result)\n",
    "        \n",
    "        # 策略4：处理特殊格式（如 version{4.4.7}）\n",
    "        self._extract_special_formats(text, result)\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def _extract_key_value_pairs(self, text: str, result: Dict[str, Any]):\n",
    "        \"\"\"提取键值对\"\"\"\n",
    "        # 各种键值对模式\n",
    "        patterns = [\n",
    "            # \"key\": \"value\"\n",
    "            (r'\"([^\"]+)\"\\s*:\\s*\"([^\"]*)\"', 'string'),\n",
    "            # \"key\": number\n",
    "            (r'\"([^\"]+)\"\\s*:\\s*([-+]?\\d+\\.?\\d*)', 'number'),\n",
    "            # \"key\": boolean\n",
    "            (r'\"([^\"]+)\"\\s*:\\s*(true|false)', 'boolean'),\n",
    "            # \"key\": null\n",
    "            (r'\"([^\"]+)\"\\s*:\\s*(null)', 'null'),\n",
    "            # 'key': 'value' (单引号)\n",
    "            (r\"'([^']+)'\\s*:\\s*'([^']*)'\", 'string'),\n",
    "            # key: value (无引号的键)\n",
    "            (r'(\\w+)\\s*:\\s*\"([^\"]*)\"', 'string'),\n",
    "            (r'(\\w+)\\s*:\\s*(\\d+\\.?\\d*)', 'number'),\n",
    "            (r'(\\w+)\\s*:\\s*(true|false)', 'boolean'),\n",
    "        ]\n",
    "        \n",
    "        used_positions = set()\n",
    "        \n",
    "        for pattern, value_type in patterns:\n",
    "            for match in re.finditer(pattern, text, re.IGNORECASE):\n",
    "                # 避免重复提取同一位置的内容\n",
    "                if match.start() in used_positions:\n",
    "                    continue\n",
    "                \n",
    "                used_positions.add(match.start())\n",
    "                \n",
    "                key = match.group(1).strip()\n",
    "                value = match.group(2).strip()\n",
    "                \n",
    "                # 处理键名（保留 \"middle name\" 这样的键）\n",
    "                original_key = key\n",
    "                # 对于包含空格的键，如果不是标准的短语，才替换空格\n",
    "                if ' ' in key and len(key.split()) == 2:\n",
    "                    # 保留类似 \"middle name\" 的格式\n",
    "                    clean_key = key\n",
    "                else:\n",
    "                    # 其他情况替换空格\n",
    "                    clean_key = re.sub(r'\\s+', '_', key)\n",
    "                    clean_key = re.sub(r'[^\\w\\s_]', '', clean_key)\n",
    "                \n",
    "                if not clean_key:\n",
    "                    continue\n",
    "                \n",
    "                # 转换值的类型\n",
    "                if value_type == 'number':\n",
    "                    try:\n",
    "                        value = float(value) if '.' in value else int(value)\n",
    "                    except:\n",
    "                        value = value\n",
    "                elif value_type == 'boolean':\n",
    "                    value = value.lower() == 'true'\n",
    "                elif value_type == 'null':\n",
    "                    value = None\n",
    "                \n",
    "                # 如果键已存在，检查是否需要创建嵌套结构\n",
    "                if clean_key not in result:\n",
    "                    result[clean_key] = value\n",
    "    \n",
    "    def _extract_arrays(self, text: str, result: Dict[str, Any]):\n",
    "        \"\"\"提取数组结构\"\"\"\n",
    "        # 查找数组模式\n",
    "        array_pattern = r'(\\w*)\\s*:\\s*\\[(.*?)\\]'\n",
    "        \n",
    "        for match in re.finditer(array_pattern, text, re.DOTALL):\n",
    "            key = match.group(1).strip() or 'items'\n",
    "            array_content = match.group(2)\n",
    "            \n",
    "            # 解析数组内容\n",
    "            items = []\n",
    "            \n",
    "            # 尝试分割数组元素\n",
    "            # 先尝试按逗号分割\n",
    "            elements = re.split(r',(?=(?:[^\"]*\"[^\"]*\")*[^\"]*$)', array_content)\n",
    "            \n",
    "            for element in elements:\n",
    "                element = element.strip()\n",
    "                if not element:\n",
    "                    continue\n",
    "                \n",
    "                # 尝试解析元素\n",
    "                if element.startswith('\"') and element.endswith('\"'):\n",
    "                    items.append(element[1:-1])\n",
    "                elif element.startswith(\"'\") and element.endswith(\"'\"):\n",
    "                    items.append(element[1:-1])\n",
    "                else:\n",
    "                    # 尝试解析为数字\n",
    "                    try:\n",
    "                        if '.' in element:\n",
    "                            items.append(float(element))\n",
    "                        else:\n",
    "                            items.append(int(element))\n",
    "                    except:\n",
    "                        # 移除多余的引号并添加\n",
    "                        cleaned = element.strip('\"\\'')\n",
    "                        if cleaned:\n",
    "                            items.append(cleaned)\n",
    "            \n",
    "            if items and key not in result:\n",
    "                result[key] = items\n",
    "    \n",
    "    def _extract_nested_objects(self, text: str, result: Dict[str, Any]):\n",
    "        \"\"\"提取嵌套对象\"\"\"\n",
    "        # 查找对象模式：key: { ... }\n",
    "        object_pattern = r'(\\w+)\\s*:\\s*\\{([^{}]*(?:\\{[^{}]*\\}[^{}]*)*)\\}'\n",
    "        \n",
    "        for match in re.finditer(object_pattern, text):\n",
    "            key = match.group(1).strip()\n",
    "            object_content = match.group(2)\n",
    "            \n",
    "            # 递归解析嵌套对象\n",
    "            nested_result = self._extract_structure(object_content)\n",
    "            \n",
    "            if nested_result and key not in result:\n",
    "                result[key] = nested_result\n",
    "    \n",
    "    def _extract_special_formats(self, text: str, result: Dict[str, Any]):\n",
    "        \"\"\"提取特殊格式，如 version{4.4.7}\"\"\"\n",
    "        # 模式：word{value}\n",
    "        special_pattern = r'(\\w+)\\s*\\{([^}]+)\\}'\n",
    "        \n",
    "        for match in re.finditer(special_pattern, text):\n",
    "            key = match.group(1).strip()\n",
    "            value = match.group(2).strip()\n",
    "            \n",
    "            if key not in result:\n",
    "                # 尝试解析值\n",
    "                try:\n",
    "                    if '.' in value:\n",
    "                        result[key] = value  # 保持为字符串（版本号）\n",
    "                    else:\n",
    "                        result[key] = int(value)\n",
    "                except:\n",
    "                    result[key] = value\n",
    "        \n",
    "        # 模式：word-word-value 或 word>value\n",
    "        other_patterns = [\n",
    "            r'(\\w+)[->\\s]+(\\w+)[->\\s]+([\\w.>=<]+)',\n",
    "            r'(\\w+)\\s*[-:>]\\s*([\\w.>=<]+)',\n",
    "        ]\n",
    "        \n",
    "        for pattern in other_patterns:\n",
    "            for match in re.finditer(pattern, text):\n",
    "                if len(match.groups()) == 3:\n",
    "                    key1, key2, value = match.groups()\n",
    "                    if key1 not in result:\n",
    "                        result[key1] = {}\n",
    "                    if isinstance(result[key1], dict):\n",
    "                        result[key1][key2] = value\n",
    "                else:\n",
    "                    key, value = match.groups()\n",
    "                    if key not in result:\n",
    "                        result[key] = value\n",
    "    \n",
    "    def parse_dataframe_notreesitter(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"解析DataFrame中的code列，只添加parsed_code列\"\"\"\n",
    "        result_df = df.copy()\n",
    "        parsed_results = []\n",
    "        \n",
    "        for idx, row in result_df.iterrows():\n",
    "            code = row['code']\n",
    "            parsed = self.parse(code)\n",
    "            parsed_results.append(parsed)\n",
    "        \n",
    "        result_df['parsed_code'] = parsed_results\n",
    "        \n",
    "        return result_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tree-sitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "from typing import Any, Dict, List, Union, Optional, Tuple\n",
    "from enum import Enum\n",
    "import traceback\n",
    "\n",
    "# 解析方法枚举\n",
    "class ParseMethod(Enum):\n",
    "    TREE_SITTER = \"tree-sitter\"\n",
    "    LENIENT = \"lenient\"\n",
    "    REGEX = \"regex\"\n",
    "    FAILED = \"failed\"\n",
    "\n",
    "\n",
    "class LayeredJSONParser:\n",
    "    \"\"\"分层JSON解析器：tree-sitter -> 宽松解析器 -> 正则提取\"\"\"\n",
    "    \n",
    "    def __init__(self, verbose: bool = False):\n",
    "        \"\"\"\n",
    "        初始化解析器\n",
    "        \n",
    "        Args:\n",
    "            verbose: 是否打印详细的解析过程\n",
    "        \"\"\"\n",
    "        self.verbose = verbose\n",
    "        self.tree_sitter_available = False\n",
    "        self.lenient_parsers_available = {\n",
    "            'demjson3': False,\n",
    "            'hjson': False,\n",
    "            'json5': False\n",
    "        }\n",
    "        \n",
    "        # 尝试导入tree-sitter\n",
    "        try:\n",
    "            from tree_sitter import Language, Parser\n",
    "            import tree_sitter_json\n",
    "            self.Parser = Parser\n",
    "            self.Language = Language\n",
    "            self.tree_sitter_json = tree_sitter_json\n",
    "            self.tree_sitter_available = True\n",
    "            if self.verbose:\n",
    "                print(\"✓ tree-sitter 可用\")\n",
    "        except ImportError:\n",
    "            if self.verbose:\n",
    "                print(\"✗ tree-sitter 不可用\")\n",
    "        \n",
    "        # 尝试导入宽松解析器\n",
    "        try:\n",
    "            import demjson3\n",
    "            self.demjson3 = demjson3\n",
    "            self.lenient_parsers_available['demjson3'] = True\n",
    "            if self.verbose:\n",
    "                print(\"✓ demjson3 可用\")\n",
    "        except ImportError:\n",
    "            if self.verbose:\n",
    "                print(\"✗ demjson3 不可用\")\n",
    "        \n",
    "        try:\n",
    "            import hjson\n",
    "            self.hjson = hjson\n",
    "            self.lenient_parsers_available['hjson'] = True\n",
    "            if self.verbose:\n",
    "                print(\"✓ hjson 可用\")\n",
    "        except ImportError:\n",
    "            if self.verbose:\n",
    "                print(\"✗ hjson 不可用\")\n",
    "        \n",
    "        try:\n",
    "            import json5\n",
    "            self.json5 = json5\n",
    "            self.lenient_parsers_available['json5'] = True\n",
    "            if self.verbose:\n",
    "                print(\"✓ json5 可用\")\n",
    "        except ImportError:\n",
    "            if self.verbose:\n",
    "                print(\"✗ json5 不可用\")\n",
    "    \n",
    "    def parse(self, text: str) -> Tuple[Dict[str, Any], ParseMethod]:\n",
    "        \"\"\"\n",
    "        解析JSON文本\n",
    "        \n",
    "        Args:\n",
    "            text: 要解析的文本\n",
    "            \n",
    "        Returns:\n",
    "            (解析结果, 使用的解析方法)\n",
    "        \"\"\"\n",
    "        if not text or not isinstance(text, str):\n",
    "            return {}, ParseMethod.FAILED\n",
    "        \n",
    "        text = text.strip()\n",
    "        if not text:\n",
    "            return {}, ParseMethod.FAILED\n",
    "        \n",
    "        # 第一层：尝试 tree-sitter\n",
    "        if self.tree_sitter_available:\n",
    "            result = self._try_tree_sitter(text)\n",
    "            if result is not None and result != {}:\n",
    "                if self.verbose:\n",
    "                    print(f\"✓ tree-sitter 成功解析\")\n",
    "                return result, ParseMethod.TREE_SITTER\n",
    "            elif self.verbose:\n",
    "                print(\"✗ tree-sitter 解析失败或返回空\")\n",
    "        \n",
    "        # 第二层：尝试宽松解析器\n",
    "        result = self._try_lenient_parsers(text)\n",
    "        if result is not None:\n",
    "            if self.verbose:\n",
    "                print(f\"✓ 宽松解析器成功\")\n",
    "            return result, ParseMethod.LENIENT\n",
    "        elif self.verbose:\n",
    "            print(\"✗ 所有宽松解析器失败\")\n",
    "        \n",
    "        # 第三层：使用正则表达式提取\n",
    "        result = self._regex_extract(text)\n",
    "        if result:\n",
    "            if self.verbose:\n",
    "                print(f\"✓ 正则提取到 {len(result)} 个键值对\")\n",
    "            return result, ParseMethod.REGEX\n",
    "        \n",
    "        # 全部失败\n",
    "        if self.verbose:\n",
    "            print(\"✗ 所有方法都失败了\")\n",
    "        return {}, ParseMethod.FAILED\n",
    "    \n",
    "    def _try_tree_sitter(self, text: str) -> Optional[Dict[str, Any]]:\n",
    "        \"\"\"尝试使用tree-sitter解析\"\"\"\n",
    "        if not self.tree_sitter_available:\n",
    "            return None\n",
    "        \n",
    "        try:\n",
    "            # 预处理文本\n",
    "            preprocessed = self._preprocess_for_tree_sitter(text)\n",
    "            \n",
    "            # 创建解析器\n",
    "            parser = self.Parser()\n",
    "            language = self.Language(self.tree_sitter_json.language(), \"json\")\n",
    "            parser.set_language(language)\n",
    "            \n",
    "            # 解析\n",
    "            tree = parser.parse(bytes(preprocessed, \"utf8\"))\n",
    "            \n",
    "            # 提取数据\n",
    "            result = self._extract_from_tree_node(tree.root_node, preprocessed)\n",
    "            \n",
    "            # 确保返回字典\n",
    "            if isinstance(result, dict) and result:\n",
    "                return result\n",
    "            elif isinstance(result, list) and result:\n",
    "                return {\"items\": result}\n",
    "            elif result is not None and result != {}:\n",
    "                return {\"value\": result}\n",
    "            \n",
    "            return None\n",
    "            \n",
    "        except Exception as e:\n",
    "            if self.verbose:\n",
    "                print(f\"tree-sitter 错误: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def _preprocess_for_tree_sitter(self, text: str) -> str:\n",
    "        \"\"\"预处理文本以提高tree-sitter成功率\"\"\"\n",
    "        # 处理特殊格式\n",
    "        text = re.sub(r'(\\w+)\\s*\\{([^}]+)\\}', r'\"\\1\": \"\\2\"', text)\n",
    "        text = re.sub(r'(\\w+)\\s*>\\s*([^\\s,}]+)', r'\"\\1\": \"\\2\"', text)\n",
    "        text = re.sub(r'(\\w+)-(\\w+)-([^\\s,}]+)', r'\"\\1\": {\"\\2\": \"\\3\"}', text)\n",
    "        \n",
    "        # 移除注释\n",
    "        text = re.sub(r'//.*?$', '', text, flags=re.MULTILINE)\n",
    "        text = re.sub(r'/\\*.*?\\*/', '', text, flags=re.DOTALL)\n",
    "        \n",
    "        # 修复引号\n",
    "        text = re.sub(r\"^''\", '\"', text)\n",
    "        \n",
    "        # 确保有外层括号\n",
    "        text = text.strip()\n",
    "        if text and not text.startswith('{') and not text.startswith('['):\n",
    "            if ':' in text:\n",
    "                text = '{' + text + '}'\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    def _extract_from_tree_node(self, node, source: str) -> Any:\n",
    "        \"\"\"从tree-sitter节点提取数据\"\"\"\n",
    "        node_type = node.type\n",
    "        \n",
    "        # 叶子节点\n",
    "        if node_type == \"null\":\n",
    "            return None\n",
    "        elif node_type == \"true\":\n",
    "            return True\n",
    "        elif node_type == \"false\":\n",
    "            return False\n",
    "        elif node_type == \"number\":\n",
    "            text = source[node.start_byte:node.end_byte]\n",
    "            try:\n",
    "                return int(text) if '.' not in text else float(text)\n",
    "            except:\n",
    "                return text\n",
    "        elif node_type == \"string\":\n",
    "            text = source[node.start_byte:node.end_byte]\n",
    "            if len(text) >= 2 and text[0] in '\"\\'':\n",
    "                return text[1:-1]\n",
    "            return text\n",
    "        \n",
    "        # 复合节点\n",
    "        elif node_type == \"array\":\n",
    "            items = []\n",
    "            for child in node.children:\n",
    "                if child.type not in [\"[\", \"]\", \",\"]:\n",
    "                    value = self._extract_from_tree_node(child, source)\n",
    "                    if value is not None:\n",
    "                        items.append(value)\n",
    "            return items\n",
    "        \n",
    "        elif node_type in [\"object\", \"document\"]:\n",
    "            obj = {}\n",
    "            for child in node.children:\n",
    "                if child.type == \"pair\":\n",
    "                    key_node = child.child_by_field_name(\"key\")\n",
    "                    value_node = child.child_by_field_name(\"value\")\n",
    "                    if key_node and value_node:\n",
    "                        key = self._extract_from_tree_node(key_node, source)\n",
    "                        value = self._extract_from_tree_node(value_node, source)\n",
    "                        if isinstance(key, str):\n",
    "                            # 处理键名\n",
    "                            if ' ' in key and len(key.split()) <= 2:\n",
    "                                clean_key = key\n",
    "                            else:\n",
    "                                clean_key = re.sub(r'\\s+', '_', key)\n",
    "                            obj[clean_key] = value\n",
    "                elif child.type == \"ERROR\":\n",
    "                    # 从错误节点恢复\n",
    "                    error_text = source[child.start_byte:child.end_byte]\n",
    "                    if ':' in error_text:\n",
    "                        parts = error_text.split(':', 1)\n",
    "                        if len(parts) == 2:\n",
    "                            key = parts[0].strip().strip('\"\\'')\n",
    "                            value = parts[1].strip().strip('\"\\'')\n",
    "                            if key:\n",
    "                                obj[key] = value\n",
    "                elif child.type not in [\"{\", \"}\", \",\"]:\n",
    "                    result = self._extract_from_tree_node(child, source)\n",
    "                    if isinstance(result, dict):\n",
    "                        obj.update(result)\n",
    "            return obj\n",
    "        \n",
    "        # ERROR节点\n",
    "        elif node_type == \"ERROR\":\n",
    "            error_text = source[node.start_byte:node.end_byte]\n",
    "            return error_text.strip()\n",
    "        \n",
    "        # 递归处理子节点\n",
    "        elif node.child_count > 0:\n",
    "            for child in node.children:\n",
    "                if child.type not in [\",\", \":\", \"{\", \"}\", \"[\", \"]\"]:\n",
    "                    result = self._extract_from_tree_node(child, source)\n",
    "                    if result is not None:\n",
    "                        return result\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def _try_lenient_parsers(self, text: str) -> Optional[Dict[str, Any]]:\n",
    "        \"\"\"尝试宽松解析器\"\"\"\n",
    "        # 预处理\n",
    "        cleaned = self._light_preprocess(text)\n",
    "        \n",
    "        # 按优先级尝试各个解析器\n",
    "        parsers = [\n",
    "            ('demjson3', self._try_demjson3),\n",
    "            ('hjson', self._try_hjson),\n",
    "            ('json5', self._try_json5),\n",
    "            ('json', self._try_standard_json)\n",
    "        ]\n",
    "        \n",
    "        for parser_name, parser_func in parsers:\n",
    "            # 尝试原始文本\n",
    "            result = parser_func(text)\n",
    "            if result is not None:\n",
    "                if self.verbose:\n",
    "                    print(f\"  - {parser_name} 成功（原始文本）\")\n",
    "                return result\n",
    "            \n",
    "            # 尝试清理后的文本\n",
    "            if cleaned != text:\n",
    "                result = parser_func(cleaned)\n",
    "                if result is not None:\n",
    "                    if self.verbose:\n",
    "                        print(f\"  - {parser_name} 成功（清理后）\")\n",
    "                    return result\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def _light_preprocess(self, text: str) -> str:\n",
    "        \"\"\"轻度预处理\"\"\"\n",
    "        # 移除注释\n",
    "        text = re.sub(r'//.*?$', '', text, flags=re.MULTILINE)\n",
    "        text = re.sub(r'/\\*.*?\\*/', '', text, flags=re.DOTALL)\n",
    "        \n",
    "        # 修复明显的问题\n",
    "        text = re.sub(r\"^''\", '\"', text)\n",
    "        \n",
    "        # 确保有外层括号\n",
    "        text = text.strip()\n",
    "        if text and not text.startswith('{') and not text.startswith('['):\n",
    "            if ':' in text:\n",
    "                text = '{' + text + '}'\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    def _try_demjson3(self, text: str) -> Optional[Dict[str, Any]]:\n",
    "        \"\"\"尝试demjson3\"\"\"\n",
    "        if not self.lenient_parsers_available['demjson3']:\n",
    "            return None\n",
    "        try:\n",
    "            result = self.demjson3.decode(text)\n",
    "            return self._ensure_dict(result)\n",
    "        except:\n",
    "            return None\n",
    "    \n",
    "    def _try_hjson(self, text: str) -> Optional[Dict[str, Any]]:\n",
    "        \"\"\"尝试hjson\"\"\"\n",
    "        if not self.lenient_parsers_available['hjson']:\n",
    "            return None\n",
    "        try:\n",
    "            result = self.hjson.loads(text)\n",
    "            return self._ensure_dict(result)\n",
    "        except:\n",
    "            return None\n",
    "    \n",
    "    def _try_json5(self, text: str) -> Optional[Dict[str, Any]]:\n",
    "        \"\"\"尝试json5\"\"\"\n",
    "        if not self.lenient_parsers_available['json5']:\n",
    "            return None\n",
    "        try:\n",
    "            result = self.json5.loads(text)\n",
    "            return self._ensure_dict(result)\n",
    "        except:\n",
    "            return None\n",
    "    \n",
    "    def _try_standard_json(self, text: str) -> Optional[Dict[str, Any]]:\n",
    "        \"\"\"尝试标准json\"\"\"\n",
    "        try:\n",
    "            result = json.loads(text)\n",
    "            return self._ensure_dict(result)\n",
    "        except:\n",
    "            return None\n",
    "    \n",
    "    def _ensure_dict(self, result: Any) -> Dict[str, Any]:\n",
    "        \"\"\"确保返回字典\"\"\"\n",
    "        if isinstance(result, dict):\n",
    "            return result\n",
    "        elif isinstance(result, list):\n",
    "            return {\"items\": result}\n",
    "        else:\n",
    "            return {\"value\": result}\n",
    "    \n",
    "    def _regex_extract(self, text: str) -> Dict[str, Any]:\n",
    "        \"\"\"使用正则表达式提取\"\"\"\n",
    "        result = {}\n",
    "        \n",
    "        # 各种键值对模式\n",
    "        patterns = [\n",
    "            # 标准JSON格式\n",
    "            (r'\"([^\"]+)\"\\s*:\\s*\"([^\"]*)\"', 'string'),\n",
    "            (r'\"([^\"]+)\"\\s*:\\s*([-+]?\\d+\\.?\\d*)', 'number'),\n",
    "            (r'\"([^\"]+)\"\\s*:\\s*(true|false|null)', 'keyword'),\n",
    "            # 单引号\n",
    "            (r\"'([^']+)'\\s*:\\s*'([^']*)'\", 'string'),\n",
    "            # 无引号键\n",
    "            (r'(\\w+)\\s*:\\s*\"([^\"]*)\"', 'string'),\n",
    "            (r'(\\w+)\\s*:\\s*([-+]?\\d+\\.?\\d*)', 'number'),\n",
    "            (r'(\\w+)\\s*:\\s*(true|false|null)', 'keyword'),\n",
    "            # 特殊格式\n",
    "            (r'(\\w+)\\s*\\{([^}]+)\\}', 'string'),\n",
    "            (r'(\\w+)\\s*[:=>\\-]\\s*([^\\s,\\n]+)', 'auto'),\n",
    "        ]\n",
    "        \n",
    "        used_positions = set()\n",
    "        \n",
    "        for pattern, value_type in patterns:\n",
    "            for match in re.finditer(pattern, text, re.IGNORECASE):\n",
    "                if match.start() in used_positions:\n",
    "                    continue\n",
    "                \n",
    "                used_positions.add(match.start())\n",
    "                key = match.group(1).strip()\n",
    "                value = match.group(2).strip()\n",
    "                \n",
    "                # 清理键名\n",
    "                if ' ' in key and len(key.split()) <= 2:\n",
    "                    clean_key = key.replace(' ', '_')\n",
    "                else:\n",
    "                    clean_key = re.sub(r'\\s+', '_', key)\n",
    "                    clean_key = re.sub(r'[^\\w_]', '', clean_key)\n",
    "                \n",
    "                if not clean_key:\n",
    "                    continue\n",
    "                \n",
    "                # 转换值\n",
    "                if value_type == 'number':\n",
    "                    try:\n",
    "                        value = int(value) if '.' not in value else float(value)\n",
    "                    except:\n",
    "                        pass\n",
    "                elif value_type == 'keyword':\n",
    "                    if value.lower() == 'true':\n",
    "                        value = True\n",
    "                    elif value.lower() == 'false':\n",
    "                        value = False\n",
    "                    elif value.lower() == 'null':\n",
    "                        value = None\n",
    "                elif value_type == 'auto':\n",
    "                    if value.lower() in ['true', 'false']:\n",
    "                        value = value.lower() == 'true'\n",
    "                    elif value.lower() == 'null':\n",
    "                        value = None\n",
    "                    else:\n",
    "                        try:\n",
    "                            value = int(value) if '.' not in value else float(value)\n",
    "                        except:\n",
    "                            value = value.strip('\"\\'')\n",
    "                \n",
    "                if clean_key not in result:\n",
    "                    result[clean_key] = value\n",
    "        \n",
    "        # 提取数组\n",
    "        array_pattern = r'(\\w*)\\s*:\\s*\\[(.*?)\\]'\n",
    "        for match in re.finditer(array_pattern, text, re.DOTALL):\n",
    "            key = match.group(1).strip() or 'items'\n",
    "            if key not in result:\n",
    "                array_content = match.group(2)\n",
    "                items = []\n",
    "                \n",
    "                elements = re.split(r',(?=(?:[^\"]*\"[^\"]*\")*[^\"]*$)', array_content)\n",
    "                for element in elements:\n",
    "                    element = element.strip().strip('\"\\'')\n",
    "                    if element:\n",
    "                        try:\n",
    "                            if '.' in element:\n",
    "                                items.append(float(element))\n",
    "                            else:\n",
    "                                items.append(int(element))\n",
    "                        except:\n",
    "                            items.append(element)\n",
    "                \n",
    "                if items:\n",
    "                    result[key] = items\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def parse_dataframe_treesitter(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        解析DataFrame中的code列\n",
    "        \n",
    "        添加两列：\n",
    "        - parsed_code: 解析结果\n",
    "        - parse_method: 使用的解析方法\n",
    "        \"\"\"\n",
    "        result_df = df.copy()\n",
    "        parsed_results = []\n",
    "        parse_methods = []\n",
    "        \n",
    "        for idx, row in result_df.iterrows():\n",
    "            code = row['code']\n",
    "            \n",
    "            if self.verbose:\n",
    "                print(f\"\\n处理 {row['participantId']}...\")\n",
    "            \n",
    "            parsed, method = self.parse(code)\n",
    "            parsed_results.append(parsed)\n",
    "            parse_methods.append(method.value)\n",
    "        \n",
    "        result_df['parsed_code'] = parsed_results\n",
    "        result_df['parse_method'] = parse_methods\n",
    "        \n",
    "        return result_df\n",
    "    \n",
    "    def get_statistics(self, df: pd.DataFrame) -> Dict[str, Any]:\n",
    "        \"\"\"获取解析统计信息\"\"\"\n",
    "        if 'parse_method' not in df.columns:\n",
    "            return {}\n",
    "        \n",
    "        method_counts = df['parse_method'].value_counts().to_dict()\n",
    "        total = len(df)\n",
    "        \n",
    "        stats = {\n",
    "            'total': total,\n",
    "            'method_counts': method_counts,\n",
    "            'method_percentages': {\n",
    "                method: count / total * 100 \n",
    "                for method, count in method_counts.items()\n",
    "            },\n",
    "            'success_rate': (total - method_counts.get(ParseMethod.FAILED.value, 0)) / total * 100\n",
    "        }\n",
    "        \n",
    "        return stats\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from typing import Any, Dict, Set, Tuple\n",
    "import zss\n",
    "\n",
    "# —— 1. 扁平化 —— #\n",
    "def flatten(obj: Any, parent_key: str = \"\") -> Dict[str, Any]:\n",
    "    flat: Dict[str, Any] = {}\n",
    "    if isinstance(obj, dict):\n",
    "        for k, v in obj.items():\n",
    "            new_key = f\"{parent_key}.{k.lower()}\" if parent_key else k.lower()  # 转换为小写\n",
    "            flat.update(flatten(v, new_key))\n",
    "    elif isinstance(obj, list):\n",
    "        for i, v in enumerate(obj):\n",
    "            new_key = f\"{parent_key}[{i}]\"\n",
    "            flat.update(flatten(v, new_key))\n",
    "    else:\n",
    "        flat[parent_key] = obj\n",
    "    return flat\n",
    "\n",
    "# —— 2. PRF 计算 —— #\n",
    "def prf(pred: Set, true: Set) -> Tuple[float, float, float]:\n",
    "    tp = len(pred & true)\n",
    "    fp = len(pred - true)\n",
    "    fn = len(true - pred)\n",
    "    precision = tp / (tp + fp) if tp + fp else 0.0\n",
    "    recall    = tp / (tp + fn) if tp + fn else 0.0\n",
    "    f1        = 2 * precision * recall / (precision + recall) if precision + recall else 0.0\n",
    "    return precision, recall, f1\n",
    "\n",
    "def dict_metrics(true_dict: Dict[str, Any], pred_dict: Dict[str, Any]) -> Dict[str, Tuple[float, float, float]]:\n",
    "    t_flat = flatten(true_dict)\n",
    "    p_flat = flatten(pred_dict)\n",
    "\n",
    "    # 键\n",
    "    key_prf = prf(set(p_flat.keys()), set(t_flat.keys()))\n",
    "\n",
    "    # 值：只看 shared keys 上的值是否相等\n",
    "    shared = set(t_flat.keys()) & set(p_flat.keys())\n",
    "    matches = {k for k in shared if t_flat[k] == p_flat[k]}\n",
    "    val_precision = len(matches) / len(shared) if shared else 0.0\n",
    "    val_recall    = len(matches) / len(t_flat)  if t_flat else 0.0\n",
    "    val_f1        = 2 * val_precision * val_recall / (val_precision + val_recall) if (val_precision + val_recall) else 0.0\n",
    "\n",
    "    # 键值对\n",
    "    kv_prf = prf(set(p_flat.items()), set(t_flat.items()))\n",
    "\n",
    "    return {\n",
    "        \"key\":  key_prf,\n",
    "        \"value\": (val_precision, val_recall, val_f1),\n",
    "        \"kv\":   kv_prf\n",
    "    }\n",
    "\n",
    "# —— 3. 树编辑距离 —— #\n",
    "def dict_to_zss(node: Any, label: str = \"root\") -> zss.Node:\n",
    "    if not isinstance(node, (dict, list)):\n",
    "        return zss.Node(f\"{label}:{node}\")\n",
    "    children = []\n",
    "    if isinstance(node, dict):\n",
    "        # 忽略键的插入顺序，按字母序遍历\n",
    "        for k in sorted(node.keys()):\n",
    "            v = node[k]\n",
    "            children.append(dict_to_zss(v, label=k))\n",
    "    else:\n",
    "        for i, v in enumerate(node):\n",
    "            children.append(dict_to_zss(v, label=f\"{label}[{i}]\"))\n",
    "    return zss.Node(label, children)\n",
    "\n",
    "def tree_metrics(true_dict: Dict[str, Any], pred_dict: Dict[str, Any]) -> Dict[str, float]:\n",
    "    t1 = dict_to_zss(true_dict, \"root\")\n",
    "    t2 = dict_to_zss(pred_dict, \"root\")\n",
    "    dist = zss.simple_distance(t1, t2)\n",
    "    def count(n: zss.Node) -> int:\n",
    "        return 1 + sum(count(c) for c in n.children)\n",
    "    size1, size2 = count(t1), count(t2)\n",
    "    norm = dist / max(size1, size2)\n",
    "    return {\n",
    "        \"ted\": dist,\n",
    "        \"normalized_ted\": norm,\n",
    "        \"similarity\": 1 - norm\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "# 假设 df 已包含 parser.parse_dataframe 的结果\n",
    "# 且 df['parsed_code'] 是 dict 类型\n",
    "def compute_metrics(row, truth):\n",
    "    user = row['parsed_code'] or {}\n",
    "    dm = dict_metrics(truth, user)\n",
    "    tm = tree_metrics(truth, user)\n",
    "    return pd.Series({\n",
    "        # key PRF\n",
    "        'key_precision':  dm['key'][0],\n",
    "        'key_recall':     dm['key'][1],\n",
    "        'key_f1':         dm['key'][2],\n",
    "        # value PRF\n",
    "        'value_precision': dm['value'][0],\n",
    "        'value_recall':    dm['value'][1],\n",
    "        'value_f1':        dm['value'][2],\n",
    "        # kv PRF\n",
    "        'kv_precision':   dm['kv'][0],\n",
    "        'kv_recall':      dm['kv'][1],\n",
    "        'kv_f1':          dm['kv'][2],\n",
    "        # tree-edit\n",
    "        'ted':            tm['ted'],\n",
    "        'normalized_ted': tm['normalized_ted'],\n",
    "        'tree_similarity':tm['similarity']\n",
    "    })\n",
    "\n",
    "def run_semantic_pipeline(\n",
    "    data_df: pd.DataFrame,\n",
    "    truth_dict: dict,\n",
    "    output_dir: str,\n",
    "    data_name: str,\n",
    "    parser_type: str = \"nt\",\n",
    "    verbose: bool = False\n",
    "):\n",
    "    \"\"\"\n",
    "    通用的语义解析 + 指标计算 + 保存流程\n",
    "\n",
    "    Args:\n",
    "      data_df:         待解析的 DataFrame，必须包含 'parsed_code' 列\n",
    "      truth_dict:      真值 dict\n",
    "      output_dir:      保存结果的目录\n",
    "      data_name:       用于构建文件名的前缀，比如 'writing_tabular_hjson'\n",
    "      parser_type:     'nt' 表示不走 tree-sitter (CleanJSONParser.parse_dataframe_notreesitter)\n",
    "                       't'  表示走 tree-sitter  (LayeredJSONParser.parse_dataframe_treesitter)\n",
    "      verbose:         如果 True，则给 LayeredJSONParser 传入 verbose=True\n",
    "\n",
    "    Returns:\n",
    "      完整的结果 DataFrame (parse + metrics)，同时也写了 CSV 到 disk\n",
    "    \"\"\"\n",
    "    # 动态选择 parser 并执行 parse\n",
    "    if parser_type == \"nt\":\n",
    "        # from your_module import CleanJSONParser  # 替换成你实际导入路径\n",
    "        parser = CleanJSONParser()\n",
    "        result_df = parser.parse_dataframe_notreesitter(data_df)\n",
    "        suffix = \"nt\"\n",
    "    elif parser_type == \"t\":\n",
    "        # from your_module import LayeredJSONParser  # 替换成你实际导入路径\n",
    "        parser = LayeredJSONParser(verbose=verbose)\n",
    "        result_df = parser.parse_dataframe_treesitter(data_df)\n",
    "        suffix = \"t\"\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown parser_type: {parser_type!r}, must be 'nt' or 't'\")\n",
    "\n",
    "    # 计算指标\n",
    "    metrics_df = result_df.apply(lambda row: compute_metrics(row, truth_dict), axis=1)\n",
    "\n",
    "    # 合并\n",
    "    full_df = pd.concat([result_df, metrics_df], axis=1)\n",
    "\n",
    "    # 确保输出目录存在\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # 构造文件名并保存\n",
    "    filename = f\"{data_name}_{suffix}_result.csv\"\n",
    "    out_path = os.path.join(output_dir, filename)\n",
    "    full_df.to_csv(out_path, index=False)\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Saved results to {out_path}\")\n",
    "\n",
    "    return full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved results to /Users/shiyi.he/Desktop/PARSER/writing_tabular_json_result_nt_result.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participantId</th>\n",
       "      <th>format</th>\n",
       "      <th>code</th>\n",
       "      <th>parsed_code</th>\n",
       "      <th>key_precision</th>\n",
       "      <th>key_recall</th>\n",
       "      <th>key_f1</th>\n",
       "      <th>value_precision</th>\n",
       "      <th>value_recall</th>\n",
       "      <th>value_f1</th>\n",
       "      <th>kv_precision</th>\n",
       "      <th>kv_recall</th>\n",
       "      <th>kv_f1</th>\n",
       "      <th>ted</th>\n",
       "      <th>normalized_ted</th>\n",
       "      <th>tree_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>66475d6f7b27e4443ef0d031</td>\n",
       "      <td>json</td>\n",
       "      <td>{\\r\\n    patients\\r\\n    if(name)=John\\r\\n    ...</td>\n",
       "      <td>{'then': 'tests,\r\n",
       "        if(id)=1,\r\n",
       "        t...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>67e571bef6af7ecd9c29ad72</td>\n",
       "      <td>json</td>\n",
       "      <td>{\\r\\n    \"patients\" : [\\r\\n     {\\r\\n         ...</td>\n",
       "      <td>{'patients': [{'name': 'John', 'tests': [{'id'...</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>60f1f1d4ac991a259b83f603</td>\n",
       "      <td>json</td>\n",
       "      <td>Note: Different colors represent different lev...</td>\n",
       "      <td>{'Different': {'colors': 'represent'}, 'differ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.230769</td>\n",
       "      <td>-0.230769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>673c13c9d37c8a73bc80b8ce</td>\n",
       "      <td>json</td>\n",
       "      <td>{\\r\\n    \"patient\" : {\\r\\n        \"name\" : \"Jo...</td>\n",
       "      <td>{'name': 'John', 'Id': '1', 'results': 'Normal...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>667ac09492ea0caadf488520</td>\n",
       "      <td>json</td>\n",
       "      <td>Name\\r\\n\" John\"\\r\\n\"ID\"(1\\r\\n\"Results\"(normal)...</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>67debe02a893eea51e8d02f2</td>\n",
       "      <td>json</td>\n",
       "      <td>{\\r\\n    \"patients\"\\r\\n    \"name\":\"John\"\\r\\n\\r...</td>\n",
       "      <td>{'name': 'John', 'results': 'normal', 'Treatme...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>615200d54efc832849db2259</td>\n",
       "      <td>json</td>\n",
       "      <td>{\\r\\n    \"patients\":\\r\\n    {\\r\\n        \"name...</td>\n",
       "      <td>{'name': 'John', 'id': '1', 'results': 'Normal...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>66b0d065329001a04e5ae671</td>\n",
       "      <td>json</td>\n",
       "      <td>{\\r\\n    \"patients\": \\r\\n    {\\r\\n    \"name\": ...</td>\n",
       "      <td>{'name': 'John', 'result': 'normal', 'treatmen...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>5e3b5fa9255e7a37bc841135</td>\n",
       "      <td>json</td>\n",
       "      <td>{\\r\\n    \"patients\": {\\r\\n        \"name\": \"joh...</td>\n",
       "      <td>{'patients': {'name': 'Michael', 'tests': [Ord...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.388889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>5d30dfa68b1523000134878f</td>\n",
       "      <td>json</td>\n",
       "      <td>{\\r\\n    \"patients\":{\\r\\n        \"name\": \"John...</td>\n",
       "      <td>{'patients': {'name': 'Michael', 'tests': [Ord...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>67cb01a82dda2577eb6ee320</td>\n",
       "      <td>json</td>\n",
       "      <td>{\\r\\n    \"patients\": [\\r\\n        \"name\": \"Joh...</td>\n",
       "      <td>{'name': 'John', 'result': 'Normal', 'treatmen...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>67cd944859dabbd1d4552d39</td>\n",
       "      <td>json</td>\n",
       "      <td>\"person\" : {\\r\\n    \"name\" : \"John\" ,\\r\\n    \"...</td>\n",
       "      <td>{'name': 'John', 'Id': '1', 'result': 'normal'...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>57c357770e6a1f00015f6038</td>\n",
       "      <td>json</td>\n",
       "      <td>{\\r\\n    \"patients\":{\\r\\n        \"name\":\"John\"...</td>\n",
       "      <td>{'patients': {'name': 'Michael', 'tests': {'id...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>5f29eff59714081a3594a331</td>\n",
       "      <td>json</td>\n",
       "      <td>{\\r\\n    \"patient\": {\\r\\n        \"name\": \"John...</td>\n",
       "      <td>{'name': 'John', 'result': 'normal', 'treatmen...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>65be552ceed6a0595fa1feb5</td>\n",
       "      <td>json</td>\n",
       "      <td>{\\r\\n    \"patients\": [\\r\\n        {\\r\\n       ...</td>\n",
       "      <td>{'patients': [{'name': 'John', 'tests': [Order...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.722222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>667983594f7d5d70a78c6e5a</td>\n",
       "      <td>json</td>\n",
       "      <td>[  \\r\\n   {\\r\\n       \"name\": \"john\",\\r\\n     ...</td>\n",
       "      <td>{'name': 'john', 'result': 'normal\r\n",
       "         }...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>66b246951b9aefec80b7158a</td>\n",
       "      <td>json</td>\n",
       "      <td>{ \\r\\n    \"patients\": \\r\\n    {\\r\\n        \"na...</td>\n",
       "      <td>{'name': 'John', 'results': 'normal', 'treatme...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               participantId format  \\\n",
       "5   66475d6f7b27e4443ef0d031   json   \n",
       "8   67e571bef6af7ecd9c29ad72   json   \n",
       "9   60f1f1d4ac991a259b83f603   json   \n",
       "12  673c13c9d37c8a73bc80b8ce   json   \n",
       "34  667ac09492ea0caadf488520   json   \n",
       "37  67debe02a893eea51e8d02f2   json   \n",
       "44  615200d54efc832849db2259   json   \n",
       "52  66b0d065329001a04e5ae671   json   \n",
       "54  5e3b5fa9255e7a37bc841135   json   \n",
       "56  5d30dfa68b1523000134878f   json   \n",
       "68  67cb01a82dda2577eb6ee320   json   \n",
       "74  67cd944859dabbd1d4552d39   json   \n",
       "75  57c357770e6a1f00015f6038   json   \n",
       "81  5f29eff59714081a3594a331   json   \n",
       "82  65be552ceed6a0595fa1feb5   json   \n",
       "90  667983594f7d5d70a78c6e5a   json   \n",
       "97  66b246951b9aefec80b7158a   json   \n",
       "\n",
       "                                                 code  \\\n",
       "5   {\\r\\n    patients\\r\\n    if(name)=John\\r\\n    ...   \n",
       "8   {\\r\\n    \"patients\" : [\\r\\n     {\\r\\n         ...   \n",
       "9   Note: Different colors represent different lev...   \n",
       "12  {\\r\\n    \"patient\" : {\\r\\n        \"name\" : \"Jo...   \n",
       "34  Name\\r\\n\" John\"\\r\\n\"ID\"(1\\r\\n\"Results\"(normal)...   \n",
       "37  {\\r\\n    \"patients\"\\r\\n    \"name\":\"John\"\\r\\n\\r...   \n",
       "44  {\\r\\n    \"patients\":\\r\\n    {\\r\\n        \"name...   \n",
       "52  {\\r\\n    \"patients\": \\r\\n    {\\r\\n    \"name\": ...   \n",
       "54  {\\r\\n    \"patients\": {\\r\\n        \"name\": \"joh...   \n",
       "56  {\\r\\n    \"patients\":{\\r\\n        \"name\": \"John...   \n",
       "68  {\\r\\n    \"patients\": [\\r\\n        \"name\": \"Joh...   \n",
       "74  \"person\" : {\\r\\n    \"name\" : \"John\" ,\\r\\n    \"...   \n",
       "75  {\\r\\n    \"patients\":{\\r\\n        \"name\":\"John\"...   \n",
       "81  {\\r\\n    \"patient\": {\\r\\n        \"name\": \"John...   \n",
       "82  {\\r\\n    \"patients\": [\\r\\n        {\\r\\n       ...   \n",
       "90  [  \\r\\n   {\\r\\n       \"name\": \"john\",\\r\\n     ...   \n",
       "97  { \\r\\n    \"patients\": \\r\\n    {\\r\\n        \"na...   \n",
       "\n",
       "                                          parsed_code  key_precision  \\\n",
       "5   {'then': 'tests,\n",
       "        if(id)=1,\n",
       "        t...       0.000000   \n",
       "8   {'patients': [{'name': 'John', 'tests': [{'id'...       0.444444   \n",
       "9   {'Different': {'colors': 'represent'}, 'differ...       0.000000   \n",
       "12  {'name': 'John', 'Id': '1', 'results': 'Normal...       0.000000   \n",
       "34                                                 {}       0.000000   \n",
       "37  {'name': 'John', 'results': 'normal', 'Treatme...       0.000000   \n",
       "44  {'name': 'John', 'id': '1', 'results': 'Normal...       0.000000   \n",
       "52  {'name': 'John', 'result': 'normal', 'treatmen...       0.000000   \n",
       "54  {'patients': {'name': 'Michael', 'tests': [Ord...       0.000000   \n",
       "56  {'patients': {'name': 'Michael', 'tests': [Ord...       0.000000   \n",
       "68  {'name': 'John', 'result': 'Normal', 'treatmen...       0.000000   \n",
       "74  {'name': 'John', 'Id': '1', 'result': 'normal'...       0.000000   \n",
       "75  {'patients': {'name': 'Michael', 'tests': {'id...       0.000000   \n",
       "81  {'name': 'John', 'result': 'normal', 'treatmen...       0.000000   \n",
       "82  {'patients': [{'name': 'John', 'tests': [Order...       1.000000   \n",
       "90  {'name': 'john', 'result': 'normal\n",
       "         }...       0.000000   \n",
       "97  {'name': 'John', 'results': 'normal', 'treatme...       0.000000   \n",
       "\n",
       "    key_recall    key_f1  value_precision  value_recall  value_f1  \\\n",
       "5     0.000000  0.000000         0.000000      0.000000  0.000000   \n",
       "8     0.444444  0.444444         1.000000      0.444444  0.615385   \n",
       "9     0.000000  0.000000         0.000000      0.000000  0.000000   \n",
       "12    0.000000  0.000000         0.000000      0.000000  0.000000   \n",
       "34    0.000000  0.000000         0.000000      0.000000  0.000000   \n",
       "37    0.000000  0.000000         0.000000      0.000000  0.000000   \n",
       "44    0.000000  0.000000         0.000000      0.000000  0.000000   \n",
       "52    0.000000  0.000000         0.000000      0.000000  0.000000   \n",
       "54    0.000000  0.000000         0.000000      0.000000  0.000000   \n",
       "56    0.000000  0.000000         0.000000      0.000000  0.000000   \n",
       "68    0.000000  0.000000         0.000000      0.000000  0.000000   \n",
       "74    0.000000  0.000000         0.000000      0.000000  0.000000   \n",
       "75    0.000000  0.000000         0.000000      0.000000  0.000000   \n",
       "81    0.000000  0.000000         0.000000      0.000000  0.000000   \n",
       "82    0.777778  0.875000         0.714286      0.555556  0.625000   \n",
       "90    0.000000  0.000000         0.000000      0.000000  0.000000   \n",
       "97    0.000000  0.000000         0.000000      0.000000  0.000000   \n",
       "\n",
       "    kv_precision  kv_recall     kv_f1   ted  normalized_ted  tree_similarity  \n",
       "5       0.000000   0.000000  0.000000  17.0        0.944444         0.055556  \n",
       "8       0.444444   0.444444  0.444444  10.0        0.555556         0.444444  \n",
       "9       0.000000   0.000000  0.000000  32.0        1.230769        -0.230769  \n",
       "12      0.000000   0.000000  0.000000  16.0        0.888889         0.111111  \n",
       "34      0.000000   0.000000  0.000000  17.0        0.944444         0.055556  \n",
       "37      0.000000   0.000000  0.000000  16.0        0.888889         0.111111  \n",
       "44      0.000000   0.000000  0.000000  15.0        0.833333         0.166667  \n",
       "52      0.000000   0.000000  0.000000  16.0        0.888889         0.111111  \n",
       "54      0.000000   0.000000  0.000000  11.0        0.611111         0.388889  \n",
       "56      0.000000   0.000000  0.000000  10.0        0.555556         0.444444  \n",
       "68      0.000000   0.000000  0.000000  16.0        0.888889         0.111111  \n",
       "74      0.000000   0.000000  0.000000  17.0        0.944444         0.055556  \n",
       "75      0.000000   0.000000  0.000000  12.0        0.666667         0.333333  \n",
       "81      0.000000   0.000000  0.000000  16.0        0.888889         0.111111  \n",
       "82      0.714286   0.555556  0.625000   5.0        0.277778         0.722222  \n",
       "90      0.000000   0.000000  0.000000  17.0        0.944444         0.055556  \n",
       "97      0.000000   0.000000  0.000000  15.0        0.833333         0.166667  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('ground_truth_writing_tabular.json', 'r', encoding='utf-8') as f:\n",
    "    ground_truth_writing_tabular = json.load(f)\n",
    "\n",
    "output_dir = \"/Users/shiyi.he/Desktop/PARSER\"\n",
    "data_name  = \"writing_tabular_json_result\"\n",
    "\n",
    "# 不走 tree-sitter\n",
    "results_nt = run_semantic_pipeline(\n",
    "    data_df    = writing_tabular_json,\n",
    "    truth_dict = ground_truth_writing_tabular,\n",
    "    output_dir = output_dir,\n",
    "    data_name  = data_name,\n",
    "    parser_type= \"nt\",\n",
    "    verbose    = True\n",
    ")\n",
    "\n",
    "results_nt\n",
    "# # 走 tree-sitter\n",
    "# results_t  = run_semantic_pipeline(\n",
    "#     data_df    = writing_tabular_hjson,\n",
    "#     truth_dict = ground_truth_writing_tabular,\n",
    "#     output_dir = output_dir,\n",
    "#     data_name  = data_name,\n",
    "#     parser_type= \"t\",\n",
    "#     verbose    = True\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## don't use this\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import traceback\n",
    "from typing import Any, Dict, List, Optional, Tuple\n",
    "from enum import Enum\n",
    "\n",
    "# === Tree-sitter 相关 ===\n",
    "from tree_sitter import Language, Parser\n",
    "import tree_sitter_json  # pip install tree-sitter-json\n",
    "\n",
    "\n",
    "class ParseMethod(Enum):\n",
    "    TREE_SITTER = \"tree-sitter\"\n",
    "    LENIENT     = \"lenient\"\n",
    "    REGEX       = \"regex\"\n",
    "    FAILED      = \"failed\"\n",
    "\n",
    "\n",
    "class LayeredJSONParser:\n",
    "    \"\"\"分层 JSON 解析器：tree-sitter -> 宽松解析器 -> 正则提取\"\"\"\n",
    "    def __init__(self, verbose: bool = False):\n",
    "        self.verbose = verbose\n",
    "\n",
    "        # --- Tree-Sitter 初始化 ---\n",
    "        try:\n",
    "            self.Parser        = Parser\n",
    "            self.json_language = Language(tree_sitter_json.language())\n",
    "            self.tree_sitter_available = True\n",
    "            if self.verbose:\n",
    "                print(\"✓ tree-sitter 可用\")\n",
    "        except Exception as e:\n",
    "            self.tree_sitter_available = False\n",
    "            if self.verbose:\n",
    "                print(\"✗ tree-sitter 不可用:\", e)\n",
    "\n",
    "        # --- 宽松解析器可用性检测 ---\n",
    "        self.lenient_parsers_available = {'demjson3': False, 'hjson': False, 'json5': False}\n",
    "        try:\n",
    "            import demjson3\n",
    "            self.demjson3 = demjson3\n",
    "            self.lenient_parsers_available['demjson3'] = True\n",
    "            if self.verbose: print(\"✓ demjson3 可用\")\n",
    "        except ImportError:\n",
    "            if self.verbose: print(\"✗ demjson3 不可用\")\n",
    "        try:\n",
    "            import hjson\n",
    "            self.hjson = hjson\n",
    "            self.lenient_parsers_available['hjson'] = True\n",
    "            if self.verbose: print(\"✓ hjson 可用\")\n",
    "        except ImportError:\n",
    "            if self.verbose: print(\"✗ hjson 不可用\")\n",
    "        try:\n",
    "            import json5\n",
    "            self.json5 = json5\n",
    "            self.lenient_parsers_available['json5'] = True\n",
    "            if self.verbose: print(\"✓ json5 可用\")\n",
    "        except ImportError:\n",
    "            if self.verbose: print(\"✗ json5 不可用\")\n",
    "\n",
    "    def parse(self, text: str) -> Tuple[Dict[str, Any], ParseMethod]:\n",
    "        if not text or not isinstance(text, str):\n",
    "            return {}, ParseMethod.FAILED\n",
    "        text = text.strip()\n",
    "        if not text:\n",
    "            return {}, ParseMethod.FAILED\n",
    "\n",
    "        # 第一层：tree-sitter\n",
    "        if self.tree_sitter_available:\n",
    "            result = self._try_tree_sitter(text)\n",
    "            # 如果 tree-sitter 返回 {'': ''} 也视为解析失败\n",
    "            if result is not None and result != {} and not (isinstance(result, dict) and '' in result and len(result) == 1):\n",
    "                if self.verbose:\n",
    "                    print(\"✓ tree-sitter 成功解析\")\n",
    "                return result, ParseMethod.TREE_SITTER\n",
    "            elif self.verbose:\n",
    "                print(\"✗ tree-sitter 解析失败或返回空\")\n",
    "\n",
    "        # 第二层：宽松解析\n",
    "        result = self._try_lenient_parsers(text)\n",
    "        if result is not None:\n",
    "            if self.verbose:\n",
    "                print(\"✓ 宽松解析器成功\")\n",
    "            return result, ParseMethod.LENIENT\n",
    "        elif self.verbose:\n",
    "            print(\"✗ 所有宽松解析器失败\")\n",
    "\n",
    "        # 第三层：正则提取\n",
    "        result = self._regex_extract(text)\n",
    "        if result:\n",
    "            if self.verbose:\n",
    "                print(f\"✓ 正则提取到 {len(result)} 个键值对\")\n",
    "            return result, ParseMethod.REGEX\n",
    "\n",
    "        # 全部失败\n",
    "        if self.verbose:\n",
    "            print(\"✗ 所有方法都失败了\")\n",
    "        return {}, ParseMethod.FAILED\n",
    "\n",
    "    def _try_tree_sitter(self, text: str) -> Optional[Dict[str, Any]]:\n",
    "        if not self.tree_sitter_available:\n",
    "            return None\n",
    "        try:\n",
    "            pre    = self._preprocess_for_tree_sitter(text)\n",
    "            parser = self.Parser(self.json_language)\n",
    "            tree   = parser.parse(bytes(pre, \"utf8\"))\n",
    "            result = self._extract_from_tree_node(tree.root_node, pre)\n",
    "            # 返回符合类型的结果\n",
    "            if isinstance(result, dict) and result:\n",
    "                return result\n",
    "            if isinstance(result, list) and result:\n",
    "                return {\"items\": result}\n",
    "            if result is not None and result != {}:\n",
    "                return {\"value\": result}\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            if self.verbose:\n",
    "                print(\"tree-sitter 错误:\", e)\n",
    "            return None\n",
    "\n",
    "    def _preprocess_for_tree_sitter(self, text: str) -> str:\n",
    "        t = re.sub(r'//.*?$', '', text, flags=re.MULTILINE)\n",
    "        t = re.sub(r'/\\*.*?\\*/', '', t, flags=re.DOTALL)\n",
    "        t = t.strip()\n",
    "        if t and not (t.startswith(\"{\") or t.startswith(\"[\")) and \":\" in t:\n",
    "            t = \"{\" + t + \"}\"\n",
    "        return t\n",
    "\n",
    "    def _extract_from_tree_node(self, node, src: str) -> Any:\n",
    "        t = node.type\n",
    "        if t == \"null\":  return None\n",
    "        if t == \"true\":  return True\n",
    "        if t == \"false\": return False\n",
    "        if t == \"number\":\n",
    "            txt = src[node.start_byte:node.end_byte]\n",
    "            try:\n",
    "                return int(txt) if \".\" not in txt else float(txt)\n",
    "            except:\n",
    "                return txt\n",
    "        if t == \"string\":\n",
    "            txt = src[node.start_byte:node.end_byte]\n",
    "            return txt[1:-1] if len(txt) >= 2 else txt\n",
    "\n",
    "        if t == \"array\":\n",
    "            items = []\n",
    "            for c in node.children:\n",
    "                if c.type not in [\"[\", \"]\", \",\"]:\n",
    "                    v = self._extract_from_tree_node(c, src)\n",
    "                    if v is not None:\n",
    "                        items.append(v)\n",
    "            return items\n",
    "\n",
    "        if t in [\"object\", \"document\"]:\n",
    "            obj = {}\n",
    "            for c in node.children:\n",
    "                if c.type == \"pair\":\n",
    "                    k   = c.child_by_field_name(\"key\")\n",
    "                    v   = c.child_by_field_name(\"value\")\n",
    "                    key = self._extract_from_tree_node(k, src)\n",
    "                    val = self._extract_from_tree_node(v, src)\n",
    "                    if isinstance(key, str):\n",
    "                        key_clean = re.sub(r\"\\s+\", \"_\", key)\n",
    "                        obj[key_clean] = val\n",
    "                elif c.type == \"ERROR\":\n",
    "                    txt = src[c.start_byte:c.end_byte]\n",
    "                    if \":\" in txt:\n",
    "                        parts = [p.strip().strip(\"\\\"'\") for p in txt.split(\":\", 1)]\n",
    "                        if len(parts) == 2:\n",
    "                            obj[parts[0]] = parts[1]\n",
    "            return obj\n",
    "\n",
    "        for c in node.children:\n",
    "            if c.type not in [\",\", \":\", \"{\", \"}\", \"[\", \"]\"]:\n",
    "                r = self._extract_from_tree_node(c, src)\n",
    "                if r is not None:\n",
    "                    return r\n",
    "        return None\n",
    "\n",
    "    def _try_lenient_parsers(self, text: str) -> Optional[Dict[str, Any]]:\n",
    "        clean = self._light_preprocess(text)\n",
    "        for fn in [self._try_demjson3, self._try_hjson, self._try_json5, self._try_standard_json]:\n",
    "            res = fn(text)\n",
    "            if res is None and clean != text:\n",
    "                res = fn(clean)\n",
    "            if res is not None:\n",
    "                return res\n",
    "        return None\n",
    "\n",
    "    def _light_preprocess(self, text: str) -> str:\n",
    "        t = re.sub(r'//.*?$', '', text, flags=re.MULTILINE)\n",
    "        t = re.sub(r'/\\*.*?\\*/', '', t, flags=re.DOTALL)\n",
    "        t = t.strip()\n",
    "        if t and not (t.startswith(\"{\") or t.startswith(\"[\")) and \":\" in t:\n",
    "            t = \"{\" + t + \"}\"\n",
    "        return t\n",
    "\n",
    "    def _try_demjson3(self, text: str) -> Optional[Dict[str, Any]]:\n",
    "        if not self.lenient_parsers_available['demjson3']:\n",
    "            return None\n",
    "        try:\n",
    "            return self._ensure_dict(self.demjson3.decode(text))\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "    def _try_hjson(self, text: str) -> Optional[Dict[str, Any]]:\n",
    "        if not self.lenient_parsers_available['hjson']:\n",
    "            return None\n",
    "        try:\n",
    "            return self._ensure_dict(self.hjson.loads(text))\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "    def _try_json5(self, text: str) -> Optional[Dict[str, Any]]:\n",
    "        if not self.lenient_parsers_available['json5']:\n",
    "            return None\n",
    "        try:\n",
    "            return self._ensure_dict(self.json5.loads(text))\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "    def _try_standard_json(self, text: str) -> Optional[Dict[str, Any]]:\n",
    "        try:\n",
    "            return self._ensure_dict(json.loads(text))\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "    def _ensure_dict(self, res: Any) -> Dict[str, Any]:\n",
    "        if isinstance(res, dict): return res\n",
    "        if isinstance(res, list): return {\"items\": res}\n",
    "        return {\"value\": res}\n",
    "\n",
    "    def _regex_extract(self, text: str) -> Dict[str, Any]:\n",
    "        result = {}\n",
    "        patterns = [\n",
    "            (r'\"([^\\\"]+)\"\\s*:\\s*\"([^\\\"]*)\"', 'string'),\n",
    "            (r'\"([^\\\"]+)\"\\s*:\\s*([-+]?\\d+\\.?\\d*)', 'number'),\n",
    "            (r'\"([^\\\"]+)\"\\s*:\\s*(true|false|null)', 'keyword'),\n",
    "            (r\"'([^']+)'\\s*:\\s*'([^']*)'\", 'string'),\n",
    "            (r'(\\w+)\\s*:\\s*\"([^\\\"]*)\"', 'string'),\n",
    "            (r'(\\w+)\\s*:\\s*([-+]?\\d+\\.?\\d*)', 'number'),\n",
    "            (r'(\\w+)\\s*:\\s*(true|false|null)', 'keyword'),\n",
    "            (r'(\\w+)\\s*\\{([^}]+)\\}', 'auto'),\n",
    "            (r'(\\w+)\\s*[:=>\\-]\\s*([^\\s,}]+)', 'auto'),\n",
    "        ]\n",
    "        used = set()\n",
    "        for pat, t in patterns:\n",
    "            for m in re.finditer(pat, text, re.IGNORECASE):\n",
    "                if m.start() in used: continue\n",
    "                used.add(m.start())\n",
    "                k, v = m.group(1).strip(), m.group(2).strip()\n",
    "                key = re.sub(r\"\\s+\", \"_\", k)\n",
    "                if t == 'number':\n",
    "                    try: v = int(v) if '.' not in v else float(v)\n",
    "                    except: pass\n",
    "                if t == 'keyword':\n",
    "                    lk = v.lower()\n",
    "                    v = True if lk=='true' else False if lk=='false' else None\n",
    "                if key and key not in result:\n",
    "                    result[key] = v\n",
    "        for m in re.finditer(r'(\\w*)\\s*:\\s*\\[(.*?)\\]', text, re.DOTALL):\n",
    "            key = m.group(1).strip() or 'items'\n",
    "            if key not in result:\n",
    "                arr = []\n",
    "                for e in re.split(r',(?=(?:[^\\\"]*\"[^\\\"]*\")*[^\\\"]*$)', m.group(2)):\n",
    "                    e = e.strip().strip(\"'\\\"\")\n",
    "                    if e:\n",
    "                        try:\n",
    "                            arr.append(int(e) if '.' not in e else float(e))\n",
    "                        except:\n",
    "                            arr.append(e)\n",
    "                result[key] = arr\n",
    "        return result\n",
    "\n",
    "    def parse_dataframe(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        df2 = df.copy()\n",
    "        parsed, methods, successes = [], [], []\n",
    "        for _, row in df2.iterrows():\n",
    "            if self.verbose:\n",
    "                print(f\"\\n处理 {row.get('participantId','')} …\")\n",
    "            res, m = self.parse(row['code'])\n",
    "            parsed.append(res)\n",
    "            methods.append(m.value)\n",
    "            successes.append(m != ParseMethod.FAILED)\n",
    "        df2['parsed_code'] = parsed\n",
    "        df2['parse_method'] = methods\n",
    "        df2['parse_success'] = successes\n",
    "        return df2\n",
    "\n",
    "    def get_statistics(self, df: pd.DataFrame) -> Dict[str, Any]:\n",
    "        if 'parse_method' not in df.columns:\n",
    "            return {}\n",
    "        counts = df['parse_method'].value_counts().to_dict()\n",
    "        tot    = len(df)\n",
    "        return {\n",
    "            'total': tot,\n",
    "            'method_counts': counts,\n",
    "            'method_percentages': {k: c / tot * 100 for k, c in counts.items()},\n",
    "            'success_rate': (tot - counts.get(ParseMethod.FAILED.value, 0)) / tot * 100\n",
    "        }\n",
    "\n",
    "    # 假设 writing_config_json 是一个 DataFrame，含 participantId 和 code 列\n",
    "parser    = LayeredJSONParser(verbose=True)\n",
    "result_df_1 = parser.parse_dataframe(writing_config_jsonc)\n",
    "result_df_1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
